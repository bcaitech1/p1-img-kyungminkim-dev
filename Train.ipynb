{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "graduate-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms, models\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "import import_ipynb\n",
    "import numpy as np\n",
    "\n",
    "from DataLoader import loader_train, loader_val\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "liable-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_valid_set = int(0.3 * len(train_dataset))\n",
    "# len_train_set = len(train_dataset) - len_valid_set\n",
    "# print(len_valid_set, len_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "completed-aside",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data, valid_data = torch.utils.data.random_split(train_dataset, [len_train_set, len_valid_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "suspected-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader_train = DataLoader(train_data, batch_size = 4, shuffle = True)\n",
    "# loader_valid = DataLoader(valid_data, batch_size = 4, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "colored-cross",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "#resnet18 = models.resnet18(pretrained = True)\n",
    "#resnet18.fc = nn.Linear(in_features=512, out_features=18, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "tracked-auditor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet152 = models.resnet152(pretrained = True)\n",
    "#resnet152.fc = nn.Linear(in_features=2048, out_features=18, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "painted-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(pretrained=True)\n",
    "#vgg16.classifier[6] = nn.Linear(in_features=4096, out_features=18, bias=True)\n",
    "vgg16.classifier = nn.Sequential(\n",
    "    nn.Linear(512 * 7 * 7, 4096),\n",
    "    nn.ReLU(True),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(4096, 4096),\n",
    "    nn.ReLU(True),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(4096, 18),\n",
    ")\n",
    "\n",
    "\n",
    "# Freeze only feature parts\n",
    "#vgg16.features.requires_grad_(False)\n",
    "#for param, weight in vgg16.named_parameters():\n",
    "#    print(f\"param {param:20} required gradient? -> {weight.requires_grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "conscious-desert",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg19 = models.vgg19(pretrained=True)\n",
    "#vgg19.classifier[6] = nn.Linear(in_features=4096, out_features=18, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "brave-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficient = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "# efficient._fc = nn.Linear(in_features=1280, out_features=18, bias=True)\n",
    "#efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "adolescent-static",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initialize all weight using xavier uniform.\n",
    "For more weight initialization methods, check https://pytorch.org/docs/stable/nn.init.html  \n",
    "\"\"\" \n",
    "import torch.nn.init as init\n",
    "\n",
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.xavier_uniform_(m.weight.data)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.data.fill_(1)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0, 0.01)\n",
    "            m.bias.data.zero_()\n",
    "            \n",
    "#initialize_weights(vgg16.classifier) #classifier만 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "after-pizza",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(resnet18.parameters(), lr=0.01)#optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "found-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, optimizer, device, t_loader, v_loader):\n",
    "        self.device = device\n",
    "        self.t_loader = t_loader\n",
    "        self.v_loader = v_loader\n",
    "        self.model = model.to(device)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        update_params = [p for p in model.parameters() if p.requires_grad]\n",
    "        self.optimizer = optimizer(update_params, lr= 0.0001, momentum = 0.9, weight_decay = 0.1)\n",
    "        \n",
    "    def train_eval(self):\n",
    "        print(\"Training Start\")\n",
    "        for epoch in range(5):\n",
    "            print(epoch+1)\n",
    "            self.train_one_epoch(epoch)\n",
    "            self.test_one_epoch(epoch)\n",
    "    \n",
    "    def train_one_epoch(self,epoch):\n",
    "        self.model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, targets) in enumerate(self.t_loader):\n",
    "            inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            outputs = self.model(inputs)\n",
    "\n",
    "            loss = self.criterion(outputs, torch.max(targets,1)[1])\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                print(f\"epoch : {epoch+1}  train Loss : {running_loss / (i+1)}\")\n",
    "                running_loss = 0.0\n",
    "                \n",
    "                \n",
    "    def test_one_epoch(self,epoch):\n",
    "        self.model.eval()\n",
    "        test_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i , (inputs, targets) in enumerate(self.v_loader):\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, torch.max(targets,1)[1])\n",
    "                \n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                if i % 1000 == 0:\n",
    "                    print(f\"epoch : {epoch+1}  test Loss : {test_loss / (i+1)}\")\n",
    "                    test_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "meaningful-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.__dict__['SGD']\n",
    "trainer = Trainer(vgg16, optimizer, device, loader_train, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "acknowledged-pearl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start\n",
      "1\n",
      "epoch : 1  train Loss : 2.8396284580230713\n",
      "epoch : 1  train Loss : 1.3470734477426474\n",
      "epoch : 1  train Loss : 0.30299919056727076\n",
      "epoch : 1  train Loss : 0.17747228241052945\n",
      "epoch : 1  test Loss : 0.22437798976898193\n",
      "epoch : 1  test Loss : 0.5323929862750993\n",
      "2\n",
      "epoch : 2  train Loss : 1.7192609310150146\n",
      "epoch : 2  train Loss : 0.4452851424996204\n",
      "epoch : 2  train Loss : 0.24279298584420478\n",
      "epoch : 2  train Loss : 0.16947738827857592\n",
      "epoch : 2  test Loss : 0.37056922912597656\n",
      "epoch : 2  test Loss : 0.45154004432372635\n",
      "3\n",
      "epoch : 3  train Loss : 1.2807950973510742\n",
      "epoch : 3  train Loss : 0.543284729093343\n",
      "epoch : 3  train Loss : 0.27375950347231903\n",
      "epoch : 3  train Loss : 0.20802555943447296\n",
      "epoch : 3  test Loss : 0.34436285495758057\n",
      "epoch : 3  test Loss : 0.6120617620285962\n",
      "4\n",
      "epoch : 4  train Loss : 0.2749505937099457\n",
      "epoch : 4  train Loss : 0.6340903137642128\n",
      "epoch : 4  train Loss : 0.34723422503138873\n",
      "epoch : 4  train Loss : 0.24023833083810012\n",
      "epoch : 4  test Loss : 0.5927905440330505\n",
      "epoch : 4  test Loss : 0.6482899810683418\n",
      "5\n",
      "epoch : 5  train Loss : 0.7838269472122192\n",
      "epoch : 5  train Loss : 0.7610254140308389\n",
      "epoch : 5  train Loss : 0.39359771590428555\n",
      "epoch : 5  train Loss : 0.2702958935059257\n",
      "epoch : 5  test Loss : 0.316170334815979\n",
      "epoch : 5  test Loss : 0.7679984848295058\n"
     ]
    }
   ],
   "source": [
    "trainer.train_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "resistant-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet18.train()\n",
    "# for epoch in range(20):\n",
    "#     running_loss = 0.0\n",
    "#     for i, data in enumerate(train_loader,0):\n",
    "#         inputs, label = data\n",
    "#         inputs = inputs.to(device)\n",
    "#         label = label.to(device)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         pred = resnet18(inputs)\n",
    "#         loss = criterion(pred, torch.max(label,1)[1])\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item()\n",
    "#         #print(running_loss)\n",
    "#         if i % 1000 == 999:\n",
    "#             print(f\"epoch : {epoch+1} {i+1} loss : {running_loss / 1000}\")\n",
    "#             running_loss = 0.0\n",
    "# print(\"Finishing Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "     \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "class albumentation_TestDataset(Dataset):\n",
    "     \n",
    "    \n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "    \n",
    "        if self.transform:\n",
    "            image_transform = self.transform(image=np.array(image))['image']\n",
    "        \n",
    "        return image_transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "def albumentation_transform():\n",
    "    import albumentations as A\n",
    "    return A.Compose([\n",
    "        Resize(224,224),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0),\n",
    "        A.pytorch.ToTensorV2(p=1.0),\n",
    "    ])\n",
    "#albumentation_transform = albumentation_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "test_dir = '/opt/ml/input/data/eval'\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "# transform_al = Compose([\n",
    "#     Resize(224, 224), # Image.BILINEAR 을 적용하면 albumentaion이 적용이 안되는거 같다\n",
    "#     Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0),\n",
    "#     ToTensorV2(p=1.0),\n",
    "# ], p = 1.0)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    Resize((224, 224), Image.BILINEAR),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "dataset = TestDataset(image_paths, transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-carroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "#albumentation_dataset = albumentation_TestDataset(image_paths, albumentation_transform)\n",
    "#albumentation_loader = DataLoader(albumentation_dataset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(data_loader, model, t):\n",
    "    model.eval()\n",
    "    test_dir = '/opt/ml/input/data/eval'\n",
    "    \n",
    "    # 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "    all_predictions = []\n",
    "    for images in loader:\n",
    "        with torch.no_grad():\n",
    "            images = images.to(device)\n",
    "            pred = model(images)\n",
    "            pred = pred.argmax(dim=-1)\n",
    "            all_predictions.extend(pred.cpu().numpy())\n",
    "    submission['ans'] = all_predictions\n",
    "    sub_name = 'submission' + str(t) + '.csv'\n",
    "    # 제출할 파일을 저장합니다.\n",
    "    submission.to_csv(os.path.join(test_dir, sub_name), index=False)\n",
    "    print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(loader, vgg16, 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "biological-television",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saving success at /opt/ml/input/data/eval/model/sub21_vgg16.pth\n"
     ]
    }
   ],
   "source": [
    "#model 저장하기\n",
    "def save_model(model, name):\n",
    "    save_folder = '/opt/ml/input/data/eval/model'\n",
    "    save_path = os.path.join(save_folder, name + \".pth\")\n",
    "    \n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saving success at {save_path}\")\n",
    "    \n",
    "save_model(efficient, \"sub21_vgg16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-pixel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
