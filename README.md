# p1-img-김경민
## 마스크 착용 상태 분류

## 개요

COVID-19의 확산으로 우리나라는 물론 전 세계 사람들은 경제적, 생산적인 활동에 많은 제약을 가지게 되었습니다. 우리나라는 COVID-19 확산 방지를 위해 사회적 거리 두기를 단계적으로 시행하는 등의 많은 노력을 하고 있습니다. 과거 높은 사망률을 가진 사스(SARS)나 에볼라(Ebola)와는 달리 COVID-19의 치사율은 오히려 비교적 낮은 편에 속합니다. 그럼에도 불구하고, 이렇게 오랜 기간 동안 우리를 괴롭히고 있는 근본적인 이유는 바로 COVID-19의 강력한 전염력 때문입니다.

감염자의 입, 호흡기로부터 나오는 비말, 침 등으로 인해 다른 사람에게 쉽게 전파가 될 수 있기 때문에 감염 확산 방지를 위해 무엇보다 중요한 것은 모든 사람이 마스크로 코와 입을 가려서 혹시 모를 감염자로부터의 전파 경로를 원천 차단하는 것입니다. 이를 위해 공공 장소에 있는 사람들은 반드시 마스크를 착용해야 할 필요가 있으며, 무엇 보다도 코와 입을 완전히 가릴 수 있도록 올바르게 착용하는 것이 중요합니다. 하지만 넓은 공공장소에서 모든 사람들의 올바른 마스크 착용 상태를 검사하기 위해서는 추가적인 인적자원이 필요할 것입니다.

따라서, 우리는 카메라로 비춰진 사람 얼굴 이미지 만으로 이 사람이 마스크를 쓰고 있는지, 쓰지 않았는지, 정확히 쓴 것이 맞는지 자동으로 가려낼 수 있는 시스템이 필요합니다. 이 시스템이 공공장소 입구에 갖춰져 있다면 적은 인적자원으로도 충분히 검사가 가능할 것입니다.


## 데이터

마스크를 착용하는 건 COIVD-19의 확산을 방지하는데 중요한 역할을 합니다. 제공되는 이 데이터셋은 사람이 마스크를 착용하였는지 판별하는 모델을 학습할 수 있게 해줍니다. 모든 데이터셋은 아시아인 남녀로 구성되어 있고 나이는 20대부터 70대까지 다양하게 분포하고 있습니다. 간략한 통계는 다음과 같습니다.

전체 사람 명 수 : 4,500

한 사람당 사진의 개수: 7 [마스크 착용 5장, 이상하게 착용(코스크, 턱스크) 1장, 미착용 1장]

이미지 크기: (384, 512)

학습 데이터와 평가 데이터를 구분하기 위해 임의로 섞어서 분할하였습니다. 60%의 사람들은 학습 데이터셋으로 활용되고, 20%는 public 테스트셋, 그리고 20%는 private 테스트셋으로 사용됩니다

진행중인 대회의 리더보드 점수는 public 테스트셋으로 계산이 됩니다. 그리고 마지막 순위는 private 테스트셋을 통해 산출한 점수로 확정됩니다. private 테스트셋의 점수는 대회가 진행되는 동안 볼 수 없습니다.

입력값. 마스크 착용 사진, 미착용 사진, 혹은 이상하게 착용한 사진(코스크, 턱스크)

![maskclass](https://github.com/bcaitech1/p1-img-kyungminkim-dev/blob/main/image/maskclass.png)

## Components

<code>DataLoader.ipynb</code>

* train데이터와 valid데이터를 만들고 albumentation을 적용. 

<code>Train.ipynb</code>

* 모델을 정의하고 학습을 진행하여 결과를 도출해냄.

<code>getLabeling.ipynb</code>

* train데이터를 읽어오고 각 이미지에 맞게 labeling을 수행.

## 평가 방법

* f1-score

![f1score](https://github.com/bcaitech1/p1-img-kyungminkim-dev/blob/main/image/f1score.png)

## 등수

accuracy : 76.2063%  
f1_score : 0.7019  
126등/224

## 최종 모델 아키텍처와 하이퍼 파라미터

학습데이터를 train data, valid data로 7 : 3비율로 나누어 학습과 평가를 진행했습니다. 

가장 성능이 높게 나온 모델은 vgg16이며 lr 이 0.001인 momentum을 사용했고 epoch은 5를 줬습니다. 이미지 사이즈는 224 X 224입니다. Batch_size는 4를 사용했습니다.

Augmentation은 Horizontalflip, shiftscalerotate, gaussnoise, HueSaturationValue, RandomBrightnessContrast를 적용했습니다. 


## 시도했지만 실패 한 것, 예상과 달랐던 것.

* Epoch 크기를 늘리면 정확도가 올라 갈거라고 생각했는데 오버 피팅이 일어나는 것 같습니다 .정확도가 오히려 떨어졌습니다. 경험상 5가 가장 좋은 epoch사이즈인 것 같습니다.
 
* 레이어가 깊은 모델을 사용하면 정확도가 오를거라고 생각했습니다. 하지만 반대로 정확도가 낮게 나왔습니다. Vgg19보다 vgg16이 더 정확도가 높았고, resnet18이 resnet152보다 정확도가 높았습니다. 레이어가 더 깊어서 학습은 더 오래 걸렸는데 정확도가 생각만큼 높지않아 실망했습니다. 

## 대회를 통해 경험한 것
데이터의 전처리의 중요성을 깨달았습니다. 모델을 아무리 수정해도 데이터의 분포가 고르지 못하면 결과가 좋게 나오지 못하는것 같습니다. 
실제 데이터를 전처리해서 정확도까지 예측하는 전 과정을 진행하면서 학습의 과정을 더 잘 이해할 수 있었습니다. 기본 예제 코드만 보고 따라 치는것 과는 다르게 왜 optimizer를 초기화 하고 loss를 backward했을 때 어떤 과정을 통해 가중치가 update되는 이해 할 수 있는 시간이 되었습니다. 

## 앞으로 더 공부할 것, 시도해보지 못한 것

cross validtaion에 대해 더 공부해봐야 할 것 같습니다. 
데이터의 전처리에 대해 더 공부하고 EDA를 통해 데이터의 어떤 부분을 가공해야 할 지를 알아내는 실력이 길러야 할 것 같습니다. 


